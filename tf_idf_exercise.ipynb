{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU5KDovsV9ez"
   },
   "source": [
    "### **About Data: Emotion Detection**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Comment\n",
    "        - Emotion\n",
    "- Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "- Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
    "\n",
    "- As there are only 3 classes, this problem comes under the **Multi-Class Classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "8ML2s0KWVXmv",
    "outputId": "4284d452-b3f4-4998-a2bf-9fd7aa273207"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>i travel i feel like men expect me to be neuro...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>i realise that although i originally started t...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>i really feel bothered about this specific iss...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>i also feel as though this assumption is rude ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>i liked it all the same this one will take a f...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>i wear this shirt i feel artistic you are arti...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>i feel like i want to stop i think of my wimpy...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>i alight in front of the hotel i can feel the ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>i feel equally wronged</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>i remember feeling so calmed and at ease becau...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "5741  i travel i feel like men expect me to be neuro...    fear\n",
       "4004  i realise that although i originally started t...    fear\n",
       "3565  i really feel bothered about this specific iss...   anger\n",
       "1204  i also feel as though this assumption is rude ...   anger\n",
       "4729  i liked it all the same this one will take a f...   anger\n",
       "4029  i wear this shirt i feel artistic you are arti...     joy\n",
       "1408  i feel like i want to stop i think of my wimpy...    fear\n",
       "4632  i alight in front of the hotel i can feel the ...     joy\n",
       "2391                             i feel equally wronged   anger\n",
       "4562  i remember feeling so calmed and at ease becau...     joy"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
    "df = pd.read_csv('Emotion_classify_Data.csv')\n",
    "#print the shape of dataframe\n",
    "df.shape\n",
    "#print top 5 rows\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joLuZmFpT-fY",
    "outputId": "77d48614-f6b3-4227-e90e-dc8ddb17381b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion\n",
       "anger    2000\n",
       "joy      2000\n",
       "fear     1937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of Emotion\n",
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qPxiqT_TT-hx",
    "outputId": "d58985b6-c81c-48b5-de9b-74735bb6b133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Emotion_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>i do enjoy large bold prints and i suppose its...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>i was able to be myself and not feel pressured...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>i should have left this movie feeling frighten...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>ive been feeling like im on shaky quilting wat...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5818</th>\n",
       "      <td>i got a feeling give it up i got a feeling get...</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>i hate getting behind because then i feel pres...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>im not going to gush too much about the relati...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>im one of girl who feel insecure about herself...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>im feeling angry i think i strop about rufflin...</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>im also feeling cranky about it because the ma...</td>\n",
       "      <td>anger</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion  Emotion_num\n",
       "4035  i do enjoy large bold prints and i suppose its...    fear            1\n",
       "4885  i was able to be myself and not feel pressured...    fear            1\n",
       "199   i should have left this movie feeling frighten...    fear            1\n",
       "1155  ive been feeling like im on shaky quilting wat...    fear            1\n",
       "5818  i got a feeling give it up i got a feeling get...   anger            2\n",
       "1891  i hate getting behind because then i feel pres...    fear            1\n",
       "1803  im not going to gush too much about the relati...     joy            0\n",
       "2561  im one of girl who feel insecure about herself...    fear            1\n",
       "4108  im feeling angry i think i strop about rufflin...   anger            2\n",
       "1582  im also feeling cranky about it because the ma...   anger            2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
    "df['Emotion_num'] = df['Emotion'].map({'joy' : 0 , 'fear' : 1 , 'anger' : 2})\n",
    "#checking the results by printing top 5 rows\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE-c0zbDXTEm"
   },
   "source": [
    "### **Modelling without Pre-processing Text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjJqi7UBT-nr"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(df['Comment'] , df['Emotion_num'] , random_state=2022 , test_size=0.2,stratify=df['Emotion_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lAD0iqGcdCn",
    "outputId": "4efb3c3c-0ad4-4501-d815-35a902095848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4749,) (1188,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGg2iXv6g40l",
    "outputId": "3f895ca5-7606-4220-b9a2-7c26d9160a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.28      0.37       400\n",
      "           1       0.37      0.81      0.51       388\n",
      "           2       0.56      0.22      0.32       400\n",
      "\n",
      "    accuracy                           0.43      1188\n",
      "   macro avg       0.50      0.44      0.40      1188\n",
      "weighted avg       0.50      0.43      0.40      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "Random_pipeline = Pipeline([\n",
    "    ('CountVectorizer' ,CountVectorizer(ngram_range=(3,3))),\n",
    "    ('Random Forest' , RandomForestClassifier())\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "Random_pipeline.fit(X_train,y_train)\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = Random_pipeline.predict(X_test)\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zetSmBrXmjM",
    "outputId": "b372f53c-8cbc-496f-ef4d-9fecff044230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       400\n",
      "           1       0.87      0.83      0.85       388\n",
      "           2       0.83      0.88      0.85       400\n",
      "\n",
      "    accuracy                           0.86      1188\n",
      "   macro avg       0.86      0.86      0.86      1188\n",
      "weighted avg       0.86      0.86      0.86      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#1. create a pipeline object\n",
    "NB_pipline = Pipeline([\n",
    "    ('CountVectorizer' ,CountVectorizer(ngram_range=(1,2))),\n",
    "    ('NB' , MultinomialNB())\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "NB_pipline.fit(X_train,y_train)\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = NB_pipline.predict(X_test)\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0dG2tc0X7SK",
    "outputId": "f6eddad9-a55b-4fde-eea2-2cbc002f6d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       400\n",
      "           1       0.93      0.87      0.90       388\n",
      "           2       0.93      0.85      0.89       400\n",
      "\n",
      "    accuracy                           0.89      1188\n",
      "   macro avg       0.90      0.89      0.89      1188\n",
      "weighted avg       0.90      0.89      0.89      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "Random_pipline = Pipeline([\n",
    "    ('CountVectorizer' ,CountVectorizer(ngram_range=(1,2))),\n",
    "    ('Random Forest' , RandomForestClassifier())\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "Random_pipline.fit(X_train,y_train)\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = Random_pipline.predict(X_test)\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmrXmL_3Z2y6"
   },
   "source": [
    "\n",
    "**Attempt 4** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using **TF-IDF vectorizer** for Pre-processing the text.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djsDsThaaCSO",
    "outputId": "b4514ab2-f6ad-45e1-b91b-e88393e975e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91       400\n",
      "           1       0.92      0.90      0.91       388\n",
      "           2       0.93      0.86      0.89       400\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#1. create a pipeline object\n",
    "Random_pipline = Pipeline([\n",
    "    ('TfidfVectorizer' ,TfidfVectorizer()),\n",
    "    ('Random Forest' , RandomForestClassifier())\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "Random_pipline.fit(X_train,y_train)\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = Random_pipline.predict(X_test)\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ACq6pDkZ4sA"
   },
   "source": [
    "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tj_xYgthX7UF"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "#use this utility function to get the preprocessed text data\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqW1i19wX7Xq"
   },
   "outputs": [],
   "source": [
    "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
    "df['text_preprocessing'] = df['Comment'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q24oRlMcai9l"
   },
   "source": [
    "**Build a model with pre processed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahdd2mgxX7dM"
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(df['text_preprocessing'] , df['Emotion_num'] , random_state=2022 , test_size=0.2,stratify=df['Emotion_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Khtu32z1XmmE",
    "outputId": "b5f67051-d0e3-4e2e-e342-8297938090ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       400\n",
      "           1       0.94      0.91      0.93       388\n",
      "           2       0.92      0.94      0.93       400\n",
      "\n",
      "    accuracy                           0.93      1188\n",
      "   macro avg       0.93      0.93      0.93      1188\n",
      "weighted avg       0.93      0.93      0.93      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "Random_pipline = Pipeline([\n",
    "    ('CountVectorizer' ,CountVectorizer(ngram_range=(1,2))),\n",
    "    ('Random Forest' , RandomForestClassifier())\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "Random_pipline.fit(X_train,y_train)\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = Random_pipline.predict(X_test)\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2y1Cy4Bauxu",
    "outputId": "ac6bf255-a218-400c-c4a9-790f4a89dfb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       400\n",
      "           1       0.93      0.93      0.93       388\n",
      "           2       0.94      0.91      0.93       400\n",
      "\n",
      "    accuracy                           0.93      1188\n",
      "   macro avg       0.93      0.93      0.93      1188\n",
      "weighted avg       0.93      0.93      0.93      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "Random_pipeline = Pipeline ([\n",
    "    ('TfidfVectorizer' ,TfidfVectorizer()),\n",
    "    ('Random Forest' , RandomForestClassifier())\n",
    "])\n",
    "#2. fit with X_train and y_train\n",
    "Random_pipeline.fit(X_train,y_train)\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = Random_pipeline.predict(X_test)\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test , y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf_idf_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
